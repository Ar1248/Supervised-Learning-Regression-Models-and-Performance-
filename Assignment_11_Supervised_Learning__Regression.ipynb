{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Supervised Learning: Regression Models and Performance Metrics | Solution\n"
      ],
      "metadata": {
        "id": "7X1Rn1wJOqnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "  - Simple Linear Regression (SLR) is a statistical technique used to model and analyze the relationship between two quantitative variables: one independent variable (predictor) and one dependent variable (outcome).\n",
        "  \n",
        "  - The method seeks to fit a straight line (the \"regression line\") through the data points in such a way that the line best predicts the values of the dependent variable based on the independent variable\n",
        "\n",
        "  - Purpose of Simple Linear Regression\n",
        "\n",
        "    - The main purpose of SLR is to estimate and understand how changes in the independent variable X are associated with changes in the dependent variable.\n",
        "\n",
        "    - SLR helps to quantify the strength and direction of this relationship, and it provides a mathematical equation (typically Y = $β_{0} + β_{1}X$ + ϵ), which can be used to make predictions about new data where only X is known.​\n",
        "\n",
        "    - SLR is valuable for both descriptive analysis (understanding relationships) and predictive modeling (forecasting outcomes)."
      ],
      "metadata": {
        "id": "24tZarHgOyGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "  - The key assumptions of Simple Linear Regression (SLR) are as follows:\n",
        "\n",
        "Linearity\n",
        "  - The relationship between the independent variable and the dependent variable must be linear, meaning that the change in the outcome should be proportional to changes in the predictor.​\n",
        "\n",
        "Independence\n",
        "  - The residuals (errors) should be independent. Observations and their errors must not be correlated with each other, ensuring valid statistical inference.​\n",
        "\n",
        "Homoscedasticity (Constant Variance)\n",
        "  - The variance of the residuals should remain constant across all levels of the independent variable. This means that the spread of errors should not increase or decrease as the predictor changes.​\n",
        "\n",
        "Normality\n",
        "  - The residuals (error terms) should be normally distributed. This is crucial for valid hypothesis testing and confidence interval estimation"
      ],
      "metadata": {
        "id": "CWegD2sgO2VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "  - The mathematical equation for a simple linear regression model is:\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <pre>\n",
        "                                                Y = B<sub>0</sub> + B<sub>1</sub>x\n",
        "  </pre>\n",
        "</div>\n",
        "\n",
        "  where,\n",
        "\n",
        " - Y =  Predicted value of the dependent variable (the response variable).\n",
        " - x = Independent variable (the predictor variable).\n",
        " - $B_{0}$=Intercept term; the expected value of Y when x=0.\n",
        " - $B_{1}$ = Slope or regression coefficient; represents the expected change in Y for a one-unit increase in x."
      ],
      "metadata": {
        "id": "FmXpP3fNR1p-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Provide a real-world example where simple linear regression can be applied.\n",
        "  - A classic real-world example where simple linear regression is applied is predicting a student's exam score based on the number of hours they studied.\n",
        "\n",
        "    - Independent Variable (x): Number of hours studied\n",
        "\n",
        "    - Dependent Variable (y): Exam score obtained\n",
        "\n",
        "  - In this scenario, historical data is collected showing how many hours different students studied and what scores they achieved. By applying simple linear regression, a best-fit line can be drawn through this data to determine the relationship between hours studied and exam score. The resulting model allows for predictions such as estimating the likely score if a student studies for 5 hours\n",
        "  - This approach helps educators and students understand the strength of the association between preparation (study time) and performance, providing actionable insight for planning study schedules."
      ],
      "metadata": {
        "id": "Fdvh0_rsSDke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. : What is the method of least squares in linear regression?\n",
        "  - The method of least squares in linear regression is a mathematical technique used to find the line of best fit for a set of data points by minimizing the sum of the squares of the differences (residuals) between the observed values and the values predicted by the line."
      ],
      "metadata": {
        "id": "DwszYs-uWBQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is Logistic Regression? How does it differ from Linear Regression?\n",
        "  - Logistic Regression is a supervised machine learning algorithm used for classification tasks, where the output (dependent variable) is categorical, typically representing binary outcomes such as yes/no or 0/1. It models the probability that a given input belongs to a certain class using the logistic (sigmoid) function, which transforms predictions to a range between 0 and 1.\n",
        "\n",
        "  - Logistic Regression Differs from Linear Regression in following aspects :\n",
        "\n",
        "    - Linear Regression\n",
        "      - Output Type : Continuous (e.g., price)\n",
        "      - Purpose : Predict values\n",
        "      - Mathematical Function : Linear equation\n",
        "      - Mathematical Function : Any real number\n",
        "      - Loss/Estimation Method : Least Squares\n",
        "      - Common Use Cases : Forecasting numbers\n",
        "    \n",
        "    - Logistic Regression\n",
        "      - Output Type : Categorical (e.g., yes/no)\n",
        "      - Purpose : \tClassify outcomes\n",
        "      - Mathematical Function : Logistic (sigmoid) function\n",
        "      - Mathematical Function : Probability (0 to 1)\n",
        "      - Loss/Estimation Method : Maximum Likelihood\n",
        "      - Common Use Cases :  Predicting class labels\n",
        "    \n",
        "  - Linear Regression predicts continuous values and fits a straight line using least squares to minimize errors.​\n",
        "\n",
        "  - Logistic Regression predicts the probability of an event and is used for classification; it uses the logistic function to map predictions to probability, and classifies based on a threshold (like 0.5)."
      ],
      "metadata": {
        "id": "G1l4fTIKWMEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Name and briefly describe three common evaluation metrics for regression models.\n",
        "  - Three common evaluation metrics for regression models are:\n",
        "\n",
        "    - Mean Absolute Error (MAE)\n",
        "      - Measures the average absolute difference between the actual values and the predicted values.\n",
        "\n",
        "      - It is easy to interpret because it is in the same units as the target variable and treats all errors equally.​\n",
        "\n",
        "    - Mean Squared Error (MSE)\n",
        "      - Calculates the average of the squared differences between actual and predicted values.\n",
        "\n",
        "      - It penalizes larger errors more heavily and is commonly used for model evaluation and optimization.​\n",
        "\n",
        "    - R-squared (R²) / Coefficient of Determination\n",
        "      - Reflects the proportion of the variance in the dependent variable that is explained by the model.\n",
        "\n",
        "      - Values range from 0 to 1, with higher values indicating a better fit of the regression model to the data.​\n",
        "\n",
        "These metrics help in understanding and comparing the predictive accuracy and explanatory power of regression models."
      ],
      "metadata": {
        "id": "5UNioxPtXnYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of the R-squared metric in regression analysis?\n",
        "  - The purpose of the R-squared metric in regression analysis is to measure the proportion of the variance in the dependent variable that is explained by the independent variable(s) in the regression model.​\n",
        "\n",
        "  - It quantifies how well the regression model fits the observed data by indicating the fraction of the total variation in the outcome that the model accounts for. R-squared values range from 0 to 1, where a value of 1 means the model perfectly explains the data variation, and 0 means it explains none of it.​\n",
        "\n",
        "  - In essence, R-squared helps assess the goodness of fit, showing how effectively the model's independent variables predict or explain the dependent variable's behavior."
      ],
      "metadata": {
        "id": "3wyTkMVDXgHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "T8lGM3zXaAgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Example data: Hours studied (X) and exam scores (y)\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable (reshape for sklearn)\n",
        "y = np.array([50, 55, 65, 70, 75])      # Dependent variable\n",
        "\n",
        "# Create the model and fit it\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Retrieve slope and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "print(f\"Slope (Coefficient): {slope:.2f}\")\n",
        "print(f\"Intercept: {intercept}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV27OrV_aI-P",
        "outputId": "1b95ac3d-8677-4f83-8e45-a93e439e62b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 6.50\n",
            "Intercept: 43.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do you interpret the coefficients in a simple linear regression model?\n",
        "  - In a simple linear regression model, the coefficients are interpreted as follows:\n",
        "\n",
        "    - The intercept (β₀) represents the expected value of the dependent variable (response) when the independent variable is zero. It serves as the baseline level of the outcome variable.​\n",
        "\n",
        "    - The slope coefficient (β₁) indicates the average change in the dependent variable for a one-unit increase in the independent variable, holding all else constant. A positive slope means the dependent variable increases as the independent variable increases, while a negative slope means it decreases."
      ],
      "metadata": {
        "id": "p6ChCECTbav4"
      }
    }
  ]
}